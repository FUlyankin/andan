{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/central-limit-theorem.png\" width=\"600\"> \n",
    "</center>\n",
    "\n",
    "[How to explain Normal Distribution to a bro at the gym](https://www.reddit.com/r/funny/comments/m4aaee/how_to_explain_normal_distribution_to_a_bro_at/)\n",
    "\n",
    "# Андан на экономе\n",
    "\n",
    "## Семинар 5: ЗБЧ, ЦПТ и метод моментов в ~~мемах~~ картинках\n",
    "\n",
    "В этом семинаре мы поговорим про сходимости, закон больших чисел и центральную предельную теорему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ЗБЧ\n",
    "\n",
    "На теории вероятностей мы говорили про ЗБЧ (закон больших чисел). Мы говорили, что он очень клёвый, так как разрешает делать кучу вещей. Давайте вспомним его формулировку: \n",
    "\n",
    "#### Слабая форма ЗБЧ (Пафнутий Львович Чебышёв)\n",
    "\n",
    "Пусть $X_1, \\ldots, X_n$ попарно независимые и одинаково распределённые случайные величины с конечным вторым моментом, $E(X_i^2) < \\infty$, тогда имеет место сходимость:\n",
    "\n",
    "$$\n",
    "\\frac{X_1 + \\ldots + X_n}{n} \\overset{p}{\\to} \\mathbb{E}(X_1)\n",
    "$$\n",
    "\n",
    "__Простым языком:__ \n",
    "\n",
    "* среднее арифметическое большого числа похожих случайных величин «стабилизируется» с рочтом их числа\n",
    "* как бы сильно случайные величины не отклонялись от своего среднего значения, эти отклонения взаимно гасятся\n",
    "* если у тебя есть страховая фирма, можно заработать бабла (самая простая формулировка) \n",
    "\n",
    "> Например, в XVI веке он впервые разрешил страховым команиям зарабатывать деньги. Люди вперввые начали составлять актуарные таблицы. Это такие таблицы, где указана ожидаемая продолжительность жизни для данного возраста и пола. Люди начали собирать данные о смертности и оценивать вероятность дожития человека до определённого возраста. На этом строились тарифы на страхование. Появление подобных таблиц обязано зарождению в течение 1600-х годов теории вероятности, которая впервые объяснила людям как случайные вещи при достаточно больших масштабах сглаживаются и становятся очень даже предсказуемыми. Надо признать, что у страхования было довольно трудное детство — как раз потому, что люди плоховато понимали концепцию вероятности. В голове довольно трудно удержать её. Многие люди и по сей день ошибочно думают, что могут влиять на случайность каким-то образом. Например, некоторые думают, что чаще других выбрасывают на кубике шестёрки. А ещё многие когнитивные искажения в нашей повседневной жизни вызваны плохим пониманием вероятности. Например, многие не понимают формулу Байеса и не могут адекватно оценить вероятность того, что [они заболели.](https://alexanderdyakonov.wordpress.com/2015/10/12/формула-байеса/) Даниэль Канеман в \"Thinking fast and slow\" пишет про разные другие когнитивные искажения, но мы чего-то отвлеклись. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 1 (рисуем ЗБЧ)\n",
    "\n",
    "__Давайте нарисуем ЗБЧ.__ Мы знаем, что математическое ожидание игральной кости это $3.5$. Сделаем симуляцию: \n",
    "\n",
    "* подкинем кость 1 раз, посчитаем среднее число на ней\n",
    "* подкинем кость 2 раза, посчитаем среднее число на ней\n",
    "\n",
    ".....\n",
    "\n",
    "* подкинем кость 100 раз, посчитаем среднее число на ней\n",
    "\n",
    "Построим картинку для всех этих средних и убедимся в том, что оно и правда сходится к $3.5$. Будем всё делать в `numpy`. Никаких циклов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сходимость по вероятности\n",
    "\n",
    "Увидели, что оно сходится? Вопрос только в том как именно. Над стрелкой в ЗБЧ есть буква $p$. \n",
    "\n",
    "$$\n",
    "\\frac{X_1 + \\ldots + X_n}{n} \\overset{p}{\\to} E(X_1)\n",
    "$$\n",
    "\n",
    "Она означает, что последовательность случайных величин слева сходится к случайной величине справа по вероятности, то есть чем больше $n$ тем ближе вероятность отклонения $\\bar x_n$ от $E(X)$ к нулю: \n",
    "\n",
    "$$ \n",
    "P(\\mid \\bar x_n - 3.5 \\mid \\ge \\varepsilon) \\to 0\n",
    "$$\n",
    "\n",
    "Давайте возьмём $\\varepsilon = 0.01$, нарисуем на нашей картинке из предыдущего упражнения коридор $3.5 \\pm \\varepsilon$, продолжим ряд до $100000$ подбрасываний и увидим, как постепенно $\\bar x_n$ попадает в коридор и всё реже выбивается из него. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 100000\n",
    "\n",
    "# подкидываем кубик с повторениями много раз\n",
    "x = np.random.choice(np.arange(1,7), size=n_obs) \n",
    "x_cumsum = np.cumsum(x)\n",
    "\n",
    "x_mean = x_cumsum/np.arange(1, n_obs + 1)\n",
    "\n",
    "eps = 0.01\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_mean[100:])\n",
    "plt.axhline(3.5 + eps, color='g', linestyle='dashed', linewidth=2)\n",
    "plt.axhline(3.5 - eps, color='g', linestyle='dashed', linewidth=2)\n",
    "\n",
    "plt.xlabel('Число подбрасываний игральной кости')\n",
    "plt.ylabel('Среднее значение');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попробовать оценить вероятность того, что последовательность из средних пробьёт на конкретном шаге установленный нами коридор. Для этого давайте сгенерируем много-много траекторий для игральной кости, как на картинке выше. А после посмотрим как часто на конкретном шаге эти траектории пробивают коридор $3.5 \\pm \\varepsilon$. Частота таких пробоин будет оценкой вероятности \n",
    "\n",
    "$$ \n",
    "P(\\mid \\bar x_n - 3.5 \\mid \\ge \\varepsilon).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 10**4\n",
    "\n",
    "# каждый раз подбрасываем кубик 1000 раз\n",
    "x = np.random.choice(np.arange(1,7), size=(n_obs, 1000))\n",
    "\n",
    "# по строкам считаем кумялятивную сумму \n",
    "x_cumsum = np.cumsum(x, axis = 0)\n",
    "\n",
    "# находим средние\n",
    "x_cumsum = x_cumsum/np.arange(1, n_obs + 1)[:,None]\n",
    "x_cumsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps1 = 0.1\n",
    "eps2 = 0.01\n",
    "\n",
    "# все события, когда пробили коридор \n",
    "bad_events_1 = np.abs(x_cumsum - 3.5) > eps1\n",
    "bad_events_2 = np.abs(x_cumsum - 3.5) > eps2\n",
    "\n",
    "# вероятность пробоины \n",
    "proba_1 = np.mean(bad_events_1, axis=1)\n",
    "proba_2 = np.mean(bad_events_2, axis=1)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(proba_1, label = f\"Вероятность для коридора {eps1}\")\n",
    "plt.plot(proba_2, label = f\"Вероятность для коридора {eps2}\")\n",
    "plt.xlabel('Число подбрасываний игральной кости')\n",
    "plt.ylabel('Вероятность пробить коридор')\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, вероятность пробить коридор поначалу является высокой, но постепенно убывает. При этом, для более узкого коридора, вероятность убывает медленнее, что логично :) \n",
    "\n",
    "Для нашей ситуации со сходимостью к константе можно построить аналогичные графики для дисперсии среднего\n",
    "\n",
    "$$\n",
    "Var(\\bar x_n) = \\frac{Var(X_1 + \\ldots  + X_n)}{n^2} = \\frac{Var(X_1)}{n}.\n",
    "$$\n",
    "\n",
    "В знаменателе у нас $n$. По мере роста выборки разброс убывает и среднее сходится к математическому ожиданию. __Важно держать в голове, что дисперсия убывает только при сходимости к константе!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, как все три картинки выглядят рядом. На них нарисовано, как среднее $\\bar x$, посчитанное по выборке $x_1, \\ldots, x_n \\sim iid N(2,1),$ сходится по вероятности к $2$. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_prob_conv.gif\" width=\"1500\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Расходимость  по вероятности\n",
    "\n",
    "\n",
    "Теперь мы знаем, как выглядит сходимость по вероятности. Интересно было бы посмотреть, как выглядит её отсутствие.\n",
    "\n",
    "Распределение Коши — тот ещё фрукт. У стандартного распределения Коши такая плотность: \n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\pi(1+x^2)}\n",
    "$$\n",
    "\n",
    "Выглядит красиво. Эта красота обманчива. У распределения Коши нет математического ожидания и дисперсии. ЗБЧ говорит нам, что для некоторых распределений \n",
    "\n",
    "$$ \n",
    "P( \\mid \\bar x - E(X)\\mid \\ge \\varepsilon  ) \\to 0, \n",
    "$$\n",
    "\n",
    "то есть выборочное среднее по вероятности сходится к математическому ожиданию. Интересно было бы узнать к чему будет сходиться выборочное среднее для распределения Коши... __Математического ожидания то не существует!__ \n",
    "\n",
    "Построим для выборочного среднего распределения Коши картинку, которую мы строили при иллюстрации ЗБЧ чуть выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy_rv = sts.cauchy()  # генератор \n",
    "\n",
    "n_obs = 10**4\n",
    "\n",
    "# 1000 траекторий по n_obs шагов\n",
    "x = cauchy_rv.rvs(size = (n_obs, 1000))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# по строкам считаем кумялятивную сумму \n",
    "x_cumsum = np.cumsum(x, axis = 0)\n",
    "\n",
    "# находим средние\n",
    "x_mean = x_cumsum/np.arange(1, n_obs + 1)[:,None]\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нарисуем одну любую траекторию\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_mean[:,442])\n",
    "plt.axhline(0, color='b', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('Число подбрасываний игральной кости')\n",
    "plt.ylabel('Среднее значение');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут может банально повести и траектория будет визуально выглядеть хорошо. Но что происходит с вероятностями? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps1 = 0.1\n",
    "eps2 = 0.01\n",
    "\n",
    "# все события, когда пробили коридор \n",
    "bad_events_1 = np.abs(x_mean - 0) > eps1\n",
    "bad_events_2 = np.abs(x_mean - 0) > eps2\n",
    "\n",
    "# вероятность пробоины \n",
    "proba_1 = np.mean(bad_events_1, axis=1)\n",
    "proba_2 = np.mean(bad_events_2, axis=1)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(proba_1)\n",
    "plt.plot(proba_2)\n",
    "plt.xlabel('Число подбрасываний игральной кости')\n",
    "plt.ylabel('Вероятность пробить коридор');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никакого движения к нулю. Постоянные пробоины в нашем коридоре. При этом, во времени их количество никак не уменьшается. Так выглядит отсутствие сходимости по вероятности. Обратите внимание, что величина пробоины не очень важна. В случае, когда сходимость есть, пробоины также могут быть очень большими, но они происходят всё реже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, как все три картинки выглядят рядом. На них изобразим первые $200$ шагов для распределения Коши. Чисто визуально сравните с первыми $200$ шагами для нормального распределения из предыдущего упражнения и ужаснитесь. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_prob_unconv.gif\" width=\"1400\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Центральная предельная теорема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЦПТ\n",
    "\n",
    "Пусть $X_1, \\ldots, X_n$ случайные величины, имеющие одинаковое распределение с конечными математическим ожиданием и дисперсией. Обычно этот факт записывают вот так:\n",
    "\n",
    "$$\n",
    "X_1, \\ldots, X_n \\sim iid(\\mu,\\sigma^2)\n",
    "$$\n",
    "\n",
    "тогда при $n \\to \\infty$ имеет место сходимость по распределению: \n",
    "\n",
    "$$\n",
    "\\sqrt{n} \\cdot \\frac{\\bar{x}_n - \\mu}{\\sigma} \\overset{d}{\\to} N(0,1)\n",
    "$$\n",
    "\n",
    "\n",
    "__Простым языком:__ \n",
    "\n",
    "* При определённых условиях сумма достаточно большого числа случайных величин имеет распределение близкое к нормальному \n",
    "* __Главное,__ чтобы случайные величины были похожи и не было такого, что одна резко выделяется на фоне остальных \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 2 (ЦПТ для равномерного)\n",
    "\n",
    "Пусть $X \\sim U[-1;1]$, пусть $Y = X_1 + \\ldots + X_n$ \n",
    "\n",
    "* Нарисуем гистограмму для $X_1$, $X_1 + X_2$,  $X_1 + X_2 + X_3$ и $X_1 + X_2 + X_3 + X_4$.\n",
    "* На последней картинке нарисуем плотность распределения $N(0,1)$ и визуально сравним, насколько сильно оно отличается от гистограммы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ващ код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже для четырёх слагаемых распределение довольно сильно напоминает $N(0,1)$. Вот так равномерное распределение будет вести себя дальше: \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_CPT_1.gif\" width=\"350\"> \n",
    "</center>\n",
    "\n",
    "Разные распределения сходятся к нормальному с разными скоростями. Например, хи-квадрат с одной степенью свободы будет сходиться дольше. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_CPT_2.gif\" width=\"350\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сходимость по распределению\n",
    "\n",
    "В ЦПТ над мы написали над стрелкой букву $d$. Она означает, что последовательность случайных величин сходится по распределению. \n",
    "\n",
    "__Определение:__ говорят, что последовательность случайных величин $X_1, X_2, \\ldots$ сходится к случайной величине $X$ _по распределению,_ если $F_{X_n}(x) \\to F_X(x)$ для всех $x$, в которых $F_X(x)$ непрерывна. Если функции сходятся, она есть. Если не сходятся, её нет.  \n",
    "\n",
    "__Пример:__ распредеелние Стьюдента при большом $n$ (число степеней свободы) становится похоже на нормальное, то есть $t(n) \\overset{d}{\\to}  N(0,1)$.\n",
    "\n",
    "Давайте это продемонстрируем: \n",
    "\n",
    "* Построим на картинке линию: плотность для $N(0,1)$.\n",
    "* Построим пять пунктирных разноцветных линий: $t(1)$, $t(2)$, $t(5)$, $t(10)$, $t(50)$.\n",
    "* Сделаем то же самое для функций распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(16, 4))\n",
    "\n",
    "for k in [1, 2, 5, 10, 50]:    \n",
    "    rv = sts.t(df=k)\n",
    "    pdf = rv.pdf(x)\n",
    "    cdf = rv.cdf(x) \n",
    "    ax[0].plot(x, pdf, label=\"$t(%s)$\" % k, lw=1.2)\n",
    "    ax[1].plot(x, cdf, label=\"$t(%s)$\" % k, lw=1.2)\n",
    "\n",
    "\n",
    "rv_limit = sts.norm( )\n",
    "pdf_limit = rv_limit.pdf(x)\n",
    "cdf_limit = rv_limit.cdf(x)\n",
    "\n",
    "ax[0].plot(x, pdf_limit, label='N(0,1)', linestyle='dashed', lw=2)\n",
    "ax[0].set_ylim(-0.03,0.45)\n",
    "ax[0].set_title(\"Плотность распределения (PDF)\")\n",
    "ax[0].legend() \n",
    "\n",
    "ax[1].set_ylim(-0.1,1.1)\n",
    "ax[1].plot(x, cdf_limit, label='N(0,1)', linestyle='dashed', lw=2)\n",
    "ax[1].set_title(\"Функция распределения (CDF)\")\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, держите гифку. Как же без неё: \n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/animation_convdist_student.gif\" width=\"1500\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Мощь средних\n",
    "\n",
    "Зачем всё это нужно? Для того, чтобы работать с выборками, оценивать параметры и строить доверительные интервалы!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примерная схема матстата \n",
    "\n",
    "__Задача:__ мы предполагаем, что какая-то штука описывается каким-то распределением с параметром $\\theta$. Чтобы понимать эту штуку, нам нужно параметр $\\theta$ оценить. __Важно:__ мы препдполагаем, что $\\theta$ - константа. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/matstat_sh.png\" width=\"750\"> \n",
    "\n",
    "__Оценивание:__ получить оценку $\\hat \\theta$ можно разными методами. Например, методом моментов или методом максимального правдоподобия. \n",
    "\n",
    "__Точечная оценка:__ Та оценка, которую мы поулчим, будет функцией от выборки, то есть слуайной величиной. Если у нас есть одна выборка, то будет одна оценка. Если другая выборка, то будет другая оценка. Нам бы хотелось понимать, насколько другой может оказаться оценка при новой выборке. Для этого нам нужно знать, как эта оценка распределена. \n",
    "\n",
    "Зная распределение оценки, мы сможем посмотреть в каком диапазоне находится $95\\%$ её вероятностной массы и сказать, что за края этого диапазона истиное значение будет вылетать редко. Этот диапозон называется доверительным интервалом. Если он получается коротким, то оценка довольно точная. Если длинным, то не очень.\n",
    "\n",
    "__Распределение оценки:__ Чтобы построить для оценки параметра доверительный интервал, нужно знать, как эта оценка распределена. Тут нам на помощь приходят разные союзники. Например, для среднего это ЦПТ. Она говорит, что среднее асимптотически нормально распределено, и мы можем использовать нормальное распределение для доверительных интервалов и проверки гипотез. Есть и другие союзники, которые помогают нам в разных ситуациях понимать, насколько точными оказались прогнозы и отвечать на вопросы. \n",
    "\n",
    "Вы их будете подробно разбирать на лекциях по матстату."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Про другие сходимости (картинка и ссылки почитать) \n",
    "\n",
    "\n",
    "На самом деле есть и другие виды сходимостей случайных величин. И между ними даже есть связи: \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hse-econ-data-science/eds_spring_2020/master/sem08_estimate_convergence/image/conv.png\" width=\"600\"> \n",
    "\n",
    "\n",
    "Пойдём с правой части кратинки в левую. \n",
    "\n",
    "* Самая слабая сходимость, __сходимость по распределению!__ Чтобы сказать, что последовательность случайных величин $X_n$ сходится по распределению к случайной величине $X$, обычно над стрелочкой пишут букву $L$ или букву $d$ или просто рисуют двойную стрелочку, $\\Rightarrow$. Из-за того, что эта сходимость самая слабая её так иногда и называют, __слабой.__\n",
    "* Сходимость чуть посильнее, это __сходимость по вероятности.__ Обычно её обозначают, подписывая над стрелкой букву $p$. Если последовательность сходится по вероятности, тогда она будет сходиться и по распределению. \n",
    "* Сходимость по вероятности, в свою очередь следует из __сходимости почти наверное__ (almost surely). Чтобы обозначить эту сходимость, над стрелкой пишут $a.s.$\n",
    "* Также сходимость по вероятности следует из __сходимости в среднем порядка $r$.__ Над стрелкой в случае такой сходимости либо подписывают порядок сходимости, либо пишут $L^r$. \n",
    "\n",
    "Последние два вида сходимостей самые сильные. Между ними нет чёткой взаимосвязи. С ними мы в этой тетрадке познакомиться не успели, но вы можете сделать это сами в почиташках! Они в README к семинару.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
